# Facial-Emotion-Recognition
# Overview of the project:
This project mainly focuses on recognizing human emotions from facial expressions by using Machine Learning. Analysing emotions from facial features is big task for machines because humans have so many different expressions. The primary goal of the project is to prepare a machine to recognize the emotions accurately. We used various methods to predict emotions, including K-Nearest Neighbors (KNN), Logistic Regression, OpenCV-based Neural Networks, and YOLO V4.

# Purpose of the project:
The main aim of this project is for developing a model which is capable to classify facial emotions. This can be applied in areas like human-computer interaction, mental health monitoring, customer experience analysis, and more. This project aims to enhance understanding and responsiveness in systems requiring emotional intelligence.

# Functionalities of the project:
- Identifying emotions like happy, sad, angry, and surprised from facial expressions in the dataset.
- Preprocessing the data, such as resizing and adjusting images, to help the model make more accurate predictions.
- Utilizing machine learning models to learn patterns from labeled datasets and evaluate their performance.
- Displaying detected faces and classified emotions on images for better interpretability and usability.

# Setup and running instructions:
# Required libraries:
To run the code, ensure the following Python libraries are installed-
- pandas
- numpy
- scikit-learn
- matplotlib
- opencv-python
- tensorflow

# Steps for executing the code:
- Install and import all the above mentioned libraries.
- Before running the code, download the following files:
    - yolov4.cfg
    - yolov4.weights
    - coco.names
- These files are needed for running the YOLO model code.
- Execute the Python script.
